

import pandas as pd
import torch
import torch.utils.data as Data
import torch.nn as nn
import torch.optim as optim
import numpy as np
import math
from tqdm import tqdm
from atom_feature import convert_to_graph_channel

# 残基到索引的映射 (添加了X表示未知氨基酸)
Pep_residue2idx = {
    '[PAD]': 0,
    '[CLS]': 1,
    '[SEP]': 2,
    'A': 3,   # Alanine
    'C': 4,   # Cysteine
    'D': 5,   # Aspartic acid
    'E': 6,   # Glutamic acid
    'F': 7,   # Phenylalanine
    'G': 8,   # Glycine
    'H': 9,   # Histidine
    'I': 10,  # Isoleucine
    'K': 11,  # Lysine
    'L': 12,  # Leucine
    'M': 13,  # Methionine
    'N': 14,  # Asparagine
    'P': 15,  # Proline
    'Q': 16,  # Glutamine
    'R': 17,  # Arginine
    'S': 18,  # Serine
    'T': 19,  # Threonine
    'V': 20,  # Valine
    'W': 21,  # Tryptophan
    'Y': 22,  # Tyrosine
    'X': 23,  # Unknown amino acid
}

def transform_Pep_to_index(sequences, residue2idx):
    token_index = []
    for seq in sequences:
        seq_id = [residue2idx.get(residue, residue2idx['X']) for residue in seq]
        token_index.append(seq_id)
    return token_index

def pad_sequence(token_list, max_len=34):
    """将序列填充到固定长度，max_len = 序列长度 + 1 (for [CLS])"""
    data = []
    for tokens in token_list:
        seq = [Pep_residue2idx['[CLS]']] + tokens
        n_pad = max_len - len(seq)
        seq.extend([Pep_residue2idx['[PAD]']] * max(n_pad, 0))
        data.append(seq[:max_len])
    return data


def load_data_from_separate_files(pos_file, neg_file, max_len=34):
    """
    从分离的正/负样本文件加载数据
    
    Args:
        pos_file: 正样本FASTA文件路径
        neg_file: 负样本FASTA文件路径
        max_len: 序列最大长度（包含[CLS]标记）
    
    Returns:
        padded_sequences, graph_features, labels
    """
    sequences = []
    labels = []
    
    # 加载正样本
    with open(pos_file, 'r') as f:
        current_seq = None
        for line in f:
            line = line.strip()
            if not line:
                continue
            if line.startswith('>'):
                current_seq = ''
                sequences.append(current_seq)
                labels.append(1)  # 正样本标签为1（已修饰）
            else:
                sequences[-1] += line.upper()
    
    # 加载负样本
    with open(neg_file, 'r') as f:
        current_seq = None
        for line in f:
            line = line.strip()
            if not line:
                continue
            if line.startswith('>'):
                current_seq = ''
                sequences.append(current_seq)
                labels.append(0)  # 负样本标签为0（未修饰）
            else:
                sequences[-1] += line.upper()
    
    # 转换序列为索引
    indexed_sequences = transform_Pep_to_index(sequences, Pep_residue2idx)
    padded_sequences = pad_sequence(indexed_sequences, max_len=max_len)
    
    # 生成图特征（带进度条）
    print(f"  正在生成图特征 ({len(sequences)} 条序列)...")
    graph_features = [convert_to_graph_channel(seq, max_seq_len=max_len-1) for seq in tqdm(sequences, desc="  处理进度")]
    
    return padded_sequences, graph_features, labels


def load_data_from_fasta(file_path, max_len=34):
    """
    从单个FASTA文件加载数据（兼容旧格式）
    标签通过header中的 'Pos|' 或 'Neg|' 来判断
    """
    sequences = []
    labels = []
    with open(file_path, 'r') as f:
        current_seq = None
        for line in f:
            line = line.strip()
            if not line:
                continue
            if line.startswith('>'):
                header = line[1:]
                # 支持新格式 "Pos|..." 和旧格式 "pos..."
                if header.lower().startswith('pos'):
                    label = 1
                else:
                    label = 0
                labels.append(label)
                current_seq = ''
                sequences.append(current_seq)
            else:
                sequences[-1] += line.upper()

    indexed_sequences = transform_Pep_to_index(sequences, Pep_residue2idx)
    padded_sequences = pad_sequence(indexed_sequences, max_len=max_len)
    
    graph_features = [convert_to_graph_channel(seq, max_seq_len=max_len-1) for seq in sequences]

    return padded_sequences, graph_features, labels


class MyDataSet(Data.Dataset):
    def __init__(self, input_ids, graph_features, labels):
        self.input_ids = input_ids
        self.graph_features = graph_features
        self.labels = labels

    def __len__(self):
        return len(self.input_ids)

    def __getitem__(self, idx):
        return (
            torch.tensor(self.input_ids[idx], dtype=torch.long),
            torch.tensor(self.graph_features[idx], dtype=torch.float),
            torch.tensor(self.labels[idx], dtype=torch.long),
        )
